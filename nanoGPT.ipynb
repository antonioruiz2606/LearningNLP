{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "file = wget.download(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('input.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the characters (character-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "str_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_str = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda string: [str_to_int[c] for c in string]\n",
    "decode = lambda integer: ''.join([int_to_str[i] for i in integer])\n",
    "\n",
    "print(encode(\"Hello world\"))\n",
    "print(decode(encode(\"Hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "trn_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Block Size (The maximum length of the context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "trn_data[:block_size+1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([18]) the output is 47\n",
      "When the input is tensor([18, 47]) the output is 56\n",
      "When the input is tensor([18, 47, 56]) the output is 57\n",
      "When the input is tensor([18, 47, 56, 57]) the output is 58\n",
      "When the input is tensor([18, 47, 56, 57, 58]) the output is 1\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1]) the output is 15\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15]) the output is 47\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the output is 58\n"
     ]
    }
   ],
   "source": [
    "x = trn_data[:block_size]\n",
    "y = trn_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'When the input is {context} the output is {target}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use blocks for computational reasons to be more efficient, but also to allow the transformer to see context of 1 to $block\\_size$ characters and predict for context of all of these lengths. This is useful because the transformer will be able to do inference with a context of length 1, and then when that length surpasses $block\\_size$ we start truncating. The transformer will never recieve more than $block\\_size$ characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "Targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "\n",
      "-------------\n",
      "\n",
      "When the input is tensor([24]), the output is 43\n",
      "When the input is tensor([24, 43]), the output is 58\n",
      "When the input is tensor([24, 43, 58]), the output is 5\n",
      "When the input is tensor([24, 43, 58,  5]), the output is 57\n",
      "When the input is tensor([24, 43, 58,  5, 57]), the output is 1\n",
      "When the input is tensor([24, 43, 58,  5, 57,  1]), the output is 46\n",
      "When the input is tensor([24, 43, 58,  5, 57,  1, 46]), the output is 43\n",
      "When the input is tensor([24, 43, 58,  5, 57,  1, 46, 43]), the output is 39\n",
      "When the input is tensor([44]), the output is 53\n",
      "When the input is tensor([44, 53]), the output is 56\n",
      "When the input is tensor([44, 53, 56]), the output is 1\n",
      "When the input is tensor([44, 53, 56,  1]), the output is 58\n",
      "When the input is tensor([44, 53, 56,  1, 58]), the output is 46\n",
      "When the input is tensor([44, 53, 56,  1, 58, 46]), the output is 39\n",
      "When the input is tensor([44, 53, 56,  1, 58, 46, 39]), the output is 58\n",
      "When the input is tensor([44, 53, 56,  1, 58, 46, 39, 58]), the output is 1\n",
      "When the input is tensor([52]), the output is 58\n",
      "When the input is tensor([52, 58]), the output is 1\n",
      "When the input is tensor([52, 58,  1]), the output is 58\n",
      "When the input is tensor([52, 58,  1, 58]), the output is 46\n",
      "When the input is tensor([52, 58,  1, 58, 46]), the output is 39\n",
      "When the input is tensor([52, 58,  1, 58, 46, 39]), the output is 58\n",
      "When the input is tensor([52, 58,  1, 58, 46, 39, 58]), the output is 1\n",
      "When the input is tensor([52, 58,  1, 58, 46, 39, 58,  1]), the output is 46\n",
      "When the input is tensor([25]), the output is 17\n",
      "When the input is tensor([25, 17]), the output is 27\n",
      "When the input is tensor([25, 17, 27]), the output is 10\n",
      "When the input is tensor([25, 17, 27, 10]), the output is 0\n",
      "When the input is tensor([25, 17, 27, 10,  0]), the output is 21\n",
      "When the input is tensor([25, 17, 27, 10,  0, 21]), the output is 1\n",
      "When the input is tensor([25, 17, 27, 10,  0, 21,  1]), the output is 54\n",
      "When the input is tensor([25, 17, 27, 10,  0, 21,  1, 54]), the output is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # How many independent sequences will be processed in parallel\n",
    "block_size = 8 # What is the maximum context length for predictions\n",
    "\n",
    "# Generate a small batch of data of inputs x and target y\n",
    "def get_batch(split):\n",
    "    data = trn_data if split == 'train' else val_data\n",
    "    chunk_idx = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in chunk_idx])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in chunk_idx])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('Inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print('Targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('\\n-------------\\n')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'When the input is {context}, the output is {target}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Bigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # Each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        return logits\n",
    "    \n",
    "model = BigramLanguageModel(vocab_size)\n",
    "out = model(xb, yb)\n",
    "print(out.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcf522520c4ab294874b08ad2d5e2f4ff47a53358720a277eb0c4174011f720e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
